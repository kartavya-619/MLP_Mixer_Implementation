{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mjUB_79aZaZ"
      },
      "source": [
        "MLP mixer proposes a way to use just mlps for vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbO0CAVuaZac"
      },
      "source": [
        "Its not better but it is competetive (at large scale) and could be researched upon ->  due to speed of infernece\n",
        "plus has better tolerence to pixel shuffling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwbn64B3aZad"
      },
      "source": [
        "It uses channel mixing and token mixing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qB0iDTaeaZae"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nm-w0oNfaZaf"
      },
      "outputs": [],
      "source": [
        "class MlpBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Standard MLP block == two linear layers and a GELU nonlinearity.\n",
        "    The first layer expands the dimension to mlp_dim, then shrinks back.\n",
        "    fc-glu-fc\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, mlp_dim):\n",
        "        super(MlpBlock, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features, mlp_dim)\n",
        "        self.fc2 = nn.Linear(mlp_dim, in_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X44VnlMZaZag"
      },
      "outputs": [],
      "source": [
        "class MixerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single Mixer block that separately mixes tokens and channels.\n",
        "    It first applies token mixing (across patches) and then channel mixing (within features).\n",
        "    part 1 then 2 in the arch diagram\n",
        "    \"\"\"\n",
        "    def __init__(self, num_tokens, hidden_dim, tokens_mlp_dim, channels_mlp_dim,drop_path=0.1):\n",
        "        super(MixerBlock, self).__init__()\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        # (1) MLP applied to the token dimension (each channel separately)\n",
        "        self.token_mixing = MlpBlock(num_tokens, tokens_mlp_dim)\n",
        "\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        # (2) MLP applied to the channel dimension (each token separately)\n",
        "        self.channel_mixing = MlpBlock(hidden_dim, channels_mlp_dim)\n",
        "        self.drop_path = drop_path\n",
        "\n",
        "\n",
        "    # def forward(self, x):\n",
        "    #     # x: (batch, num_tokens, hidden_dim)\n",
        "\n",
        "    #     \"\"\"\n",
        "    #     # Token mixing\n",
        "    #     \"\"\"\n",
        "    #     y = self.norm1(x)\n",
        "    #     y = y.transpose(1, 2)  # (B, hidden_dim, num_tokens)\n",
        "    #     y = self.token_mixing(y)\n",
        "    #     y = y.transpose(1, 2)  # back to (B, num_tokens, hidden_dim)\n",
        "    #     x = x + y  # skip connection\n",
        "    #     \"\"\"\n",
        "    #     # Channel mixing\n",
        "    #     \"\"\"\n",
        "    #     y = self.norm2(x)\n",
        "    #     y = self.channel_mixing(y)\n",
        "    #     return x + y  # skip connection\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Token mixing\n",
        "        if self.training and torch.rand(1).item() < self.drop_path:\n",
        "            y = 0\n",
        "        else:\n",
        "            y = self.norm1(x)\n",
        "            y = y.transpose(1, 2)\n",
        "            y = self.token_mixing(y)\n",
        "            y = y.transpose(1, 2)\n",
        "            if self.drop_path > 0:\n",
        "                y = y / (1 - self.drop_path)\n",
        "        x = x + y\n",
        "\n",
        "        # Channel mixing\n",
        "        if self.training and torch.rand(1).item() < self.drop_path:\n",
        "            y = 0\n",
        "        else:\n",
        "            y = self.norm2(x)\n",
        "            y = self.channel_mixing(y)\n",
        "            if self.drop_path > 0:\n",
        "                y = y / (1 - self.drop_path)\n",
        "        return x + y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F8MbfY5TaZah"
      },
      "outputs": [],
      "source": [
        "class MlpMixer(nn.Module):\n",
        "    \"\"\"\n",
        "    The full MLP-Mixer network.\n",
        "    Given an input image, it splits it into patches via a convolution (\"stem\"),\n",
        "    then processes the resulting tokens with several Mixer blocks,\n",
        "\n",
        "    applies a final layer norm-> global average pooling-> linear classifier.\n",
        "\n",
        "    Rn using CIFAR-100 (32×32 images), we set a small patch size (4×4) as imagent is too big\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, num_blocks, patch_size, hidden_dim,\n",
        "                 tokens_mlp_dim, channels_mlp_dim, image_size=32, in_channels=3):\n",
        "        super(MlpMixer, self).__init__()\n",
        "\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "        \"\"\"\n",
        "        # (1) The stem Conv2d splits the image into non-overlapping patches.\n",
        "        #     START OF THE PAPER WE SPLIT THE IMAGE INTO NON OVERLAPPING PATCH\n",
        "        #     CNN does the same sort of thing\n",
        "        \"\"\"\n",
        "        self.stem = nn.Conv2d(in_channels, hidden_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        self.num_tokens = (image_size // patch_size) ** 2\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        # (2) makes them into list of mixer block\n",
        "\n",
        "        \"\"\"\n",
        "        # Create a list of Mixer blocks.\n",
        "        self.mixer_blocks = nn.ModuleList([\n",
        "            MixerBlock(num_tokens=self.num_tokens, hidden_dim=hidden_dim,\n",
        "                       tokens_mlp_dim=tokens_mlp_dim, channels_mlp_dim=channels_mlp_dim)\n",
        "            for _ in range(num_blocks)\n",
        "        ])\n",
        "        # Final layer normalization before classifiing\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        # zero initialize the weights as in paper given\n",
        "        self.head = nn.Linear(hidden_dim, num_classes)\n",
        "        nn.init.zeros_(self.head.weight)\n",
        "        if self.head.bias is not None:\n",
        "            nn.init.zeros_(self.head.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, in_channels, image_size, image_size)\n",
        "        x = self.stem(x)  # → (B, hidden_dim, H', W') where H' = image_size/patch_size\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.flatten(2).transpose(1, 2)  # → (B, num_tokens, hidden_dim)\n",
        "        for block in self.mixer_blocks:\n",
        "            x = block(x)\n",
        "        x = self.norm(x)\n",
        "        x = x.mean(dim=1)  # global average pooling\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FrRGYv0AaZai"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "    avg_loss = running_loss / len(dataloader.dataset)\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jr0k22YLaZaj"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "class TransformSubset(torch.utils.data.Dataset):\n",
        "    \"\"\"A dataset wrapper that applies a transform to a subset.\"\"\"\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.subset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Normalization stats for CIFAR-10\n",
        "    mean = [0.4914, 0.4822, 0.4465]\n",
        "    std = [0.2470, 0.2435, 0.2616]\n",
        "\n",
        "    # Define transforms\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ])\n",
        "\n",
        "    # Load the training dataset without transforms initially\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=None)\n",
        "\n",
        "    # Split into training and validation sets\n",
        "    train_size = int(0.8 * len(trainset))  # 80% for training\n",
        "    val_size = len(trainset) - train_size  # 20% for validation\n",
        "    train_subset, val_subset = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "    # Apply transforms to each subset\n",
        "    train_dataset = TransformSubset(train_subset, transform=transform_train)\n",
        "    val_dataset = TransformSubset(val_subset, transform=transform_test)\n",
        "\n",
        "    # Create data loaders\n",
        "    trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "    valloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Load test set\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                           download=True, transform=transform_test)\n",
        "    testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTaSblu9qWDl",
        "outputId": "a50c03be-249c-4b28-bcf8-b1f1b6bb5cd0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 45.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
        "\n",
        "# Define the model for CIFAR-10\n",
        "model = MlpMixer(\n",
        "    num_classes=10,           # CIFAR-10 has 10 classes\n",
        "    num_blocks=2,\n",
        "    patch_size=4,\n",
        "    hidden_dim=512,\n",
        "    tokens_mlp_dim=256,\n",
        "    channels_mlp_dim=256,\n",
        "    image_size=32,\n",
        "    in_channels=3\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-3, weight_decay=0.05)\n",
        "\n",
        "# Warmup + Cosine Annealing Scheduler\n",
        "num_epochs = 100\n",
        "warmup_epochs = 5\n",
        "\n",
        "warmup = LinearLR(optimizer, start_factor=1e-5, total_iters=warmup_epochs)\n",
        "cosine = CosineAnnealingLR(optimizer, T_max=num_epochs - warmup_epochs)\n",
        "scheduler = SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n",
        "\n",
        "# Loss function with label smoothing for better generalization\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "# Training loop\n",
        "print(\"Starting training on CIFAR-10\")\n",
        "best_val_acc = 0\n",
        "best_model_state = None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, trainloader, criterion, optimizer, device)\n",
        "    val_acc = evaluate(model, valloader, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Val Accuracy: {val_acc * 100:.2f}%\")\n",
        "\n",
        "# Load best model and evaluate on test set\n",
        "model.load_state_dict(best_model_state)\n",
        "test_acc = evaluate(model, testloader, device)\n",
        "print(f\"\\n✅ Final Test Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzbRyNhVqshc",
        "outputId": "39b9f3b7-b853-4a8f-fd41-3dad897c4c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training on CIFAR-10\n",
            "Epoch [1/100], Loss: 2.3023, Val Accuracy: 18.97%\n",
            "Epoch [2/100], Loss: 1.8501, Val Accuracy: 45.36%\n",
            "Epoch [3/100], Loss: 1.6670, Val Accuracy: 51.71%\n",
            "Epoch [4/100], Loss: 1.5779, Val Accuracy: 56.55%\n",
            "Epoch [5/100], Loss: 1.5101, Val Accuracy: 59.20%\n",
            "Epoch [6/100], Loss: 1.4851, Val Accuracy: 60.90%\n",
            "Epoch [7/100], Loss: 1.4287, Val Accuracy: 63.29%\n",
            "Epoch [8/100], Loss: 1.3874, Val Accuracy: 65.76%\n",
            "Epoch [9/100], Loss: 1.3541, Val Accuracy: 66.32%\n",
            "Epoch [10/100], Loss: 1.3288, Val Accuracy: 66.11%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}