{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP mixer proposes a way to use just mlps for vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its not better but it is competetive (at large scale) and could be researched upon ->  due to speed of infernece\n",
    "plus has better tolerence to pixel shuffling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It uses channel mixing and token mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard MLP block == two linear layers and a GELU nonlinearity.\n",
    "    The first layer expands the dimension to mlp_dim, then shrinks back.\n",
    "    fc-glu-fc\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, mlp_dim):\n",
    "        super(MlpBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, mlp_dim)\n",
    "        self.fc2 = nn.Linear(mlp_dim, in_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A single Mixer block that separately mixes tokens and channels.\n",
    "    It first applies token mixing (across patches) and then channel mixing (within features).\n",
    "    part 1 then 2 in the arch diagram\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens, hidden_dim, tokens_mlp_dim, channels_mlp_dim,drop_path=0.1):\n",
    "        super(MixerBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        # (1) MLP applied to the token dimension (each channel separately)\n",
    "        self.token_mixing = MlpBlock(num_tokens, tokens_mlp_dim)\n",
    "        \n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        # (2) MLP applied to the channel dimension (each token separately)\n",
    "        self.channel_mixing = MlpBlock(hidden_dim, channels_mlp_dim)\n",
    "        self.drop_path = drop_path\n",
    "\n",
    "                \n",
    "    # def forward(self, x):\n",
    "    #     # x: (batch, num_tokens, hidden_dim)\n",
    "\n",
    "    #     \"\"\"\n",
    "    #     # Token mixing\n",
    "    #     \"\"\"\n",
    "    #     y = self.norm1(x)\n",
    "    #     y = y.transpose(1, 2)  # (B, hidden_dim, num_tokens)\n",
    "    #     y = self.token_mixing(y)\n",
    "    #     y = y.transpose(1, 2)  # back to (B, num_tokens, hidden_dim)\n",
    "    #     x = x + y  # skip connection\n",
    "    #     \"\"\"\n",
    "    #     # Channel mixing\n",
    "    #     \"\"\"\n",
    "    #     y = self.norm2(x)\n",
    "    #     y = self.channel_mixing(y)\n",
    "    #     return x + y  # skip connection\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Token mixing\n",
    "        if self.training and torch.rand(1).item() < self.drop_path:\n",
    "            y = 0\n",
    "        else:\n",
    "            y = self.norm1(x)\n",
    "            y = y.transpose(1, 2)\n",
    "            y = self.token_mixing(y)\n",
    "            y = y.transpose(1, 2)\n",
    "            if self.drop_path > 0:\n",
    "                y = y / (1 - self.drop_path)\n",
    "        x = x + y\n",
    "        \n",
    "        # Channel mixing\n",
    "        if self.training and torch.rand(1).item() < self.drop_path:\n",
    "            y = 0\n",
    "        else:\n",
    "            y = self.norm2(x)\n",
    "            y = self.channel_mixing(y)\n",
    "            if self.drop_path > 0:\n",
    "                y = y / (1 - self.drop_path)\n",
    "        return x + y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpMixer(nn.Module):\n",
    "    \"\"\"\n",
    "    The full MLP-Mixer network.\n",
    "    Given an input image, it splits it into patches via a convolution (\"stem\"),\n",
    "    then processes the resulting tokens with several Mixer blocks,\n",
    "\n",
    "    applies a final layer norm-> global average pooling-> linear classifier.\n",
    "    \n",
    "    Rn using CIFAR-100 (32×32 images), we set a small patch size (4×4) as imagent is too big\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, num_blocks, patch_size, hidden_dim,\n",
    "                 tokens_mlp_dim, channels_mlp_dim, image_size=32, in_channels=3):\n",
    "        super(MlpMixer, self).__init__()\n",
    "\n",
    "        \n",
    "        self.patch_size = patch_size\n",
    "        \"\"\"\n",
    "        # (1) The stem Conv2d splits the image into non-overlapping patches. \n",
    "        #     START OF THE PAPER WE SPLIT THE IMAGE INTO NON OVERLAPPING PATCH\n",
    "        #     CNN does the same sort of thing\n",
    "        \"\"\"\n",
    "        self.stem = nn.Conv2d(in_channels, hidden_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.num_tokens = (image_size // patch_size) ** 2\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        # (2) makes them into list of mixer block\n",
    "            \n",
    "        \"\"\"\n",
    "        # Create a list of Mixer blocks.\n",
    "        self.mixer_blocks = nn.ModuleList([\n",
    "            MixerBlock(num_tokens=self.num_tokens, hidden_dim=hidden_dim,\n",
    "                       tokens_mlp_dim=tokens_mlp_dim, channels_mlp_dim=channels_mlp_dim)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        # Final layer normalization before classifiing\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # zero initialize the weights as in paper given\n",
    "        self.head = nn.Linear(hidden_dim, num_classes)\n",
    "        nn.init.zeros_(self.head.weight)\n",
    "        if self.head.bias is not None:\n",
    "            nn.init.zeros_(self.head.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, in_channels, image_size, image_size)\n",
    "        x = self.stem(x)  # → (B, hidden_dim, H', W') where H' = image_size/patch_size\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)  # → (B, num_tokens, hidden_dim)\n",
    "        for block in self.mixer_blocks:\n",
    "            x = block(x)\n",
    "        x = self.norm(x)\n",
    "        x = x.mean(dim=1)  # global average pooling\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    avg_loss = running_loss / len(dataloader.dataset)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # Data augmentation and normalization for training; \n",
    "    # simple normalization for now , ask proff for better ones for smaller dataset/ larger\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5071, 0.4867, 0.4408],\n",
    "                             std=[0.2675, 0.2565, 0.2761])\n",
    "    ])\n",
    "    \"\"\"\n",
    "    Images are normalized using mean and standard deviation\n",
    "    Data Augmentation: Random Horizontal Flip\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5071, 0.4867, 0.4408],\n",
    "                             std=[0.2675, 0.2565, 0.2761])\n",
    "    ])\n",
    "    \n",
    "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                             download=True, transform=transform_train)\n",
    "    testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                            download=True, transform=transform_test)\n",
    "    \n",
    "    trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    testloader  = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on CIFAR-100\n",
      "Epoch [1/100], Loss: 4.1046, Test Accuracy: 8.71%\n",
      "Epoch [2/100], Loss: 3.8120, Test Accuracy: 14.80%\n",
      "Epoch [3/100], Loss: 3.7175, Test Accuracy: 14.27%\n",
      "Epoch [4/100], Loss: 3.7224, Test Accuracy: 14.70%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training on CIFAR-100\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 42\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m         test_acc \u001b[38;5;241m=\u001b[39m evaluate(model, testloader, device)\n\u001b[1;32m     44\u001b[0m         scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 12\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg_loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up \n",
    "    # We choose a small hidden_dim  but still get overfitting\n",
    "# model = MlpMixer(\n",
    "#         num_classes=100,     # 100 classes\n",
    "#         num_blocks=8,        \n",
    "#         patch_size=4,       \n",
    "#         hidden_dim=256,      # Hidden channel size\n",
    "#         tokens_mlp_dim=128,   # Hidden dimension for token-mixing MLP\n",
    "#         channels_mlp_dim=512, # Hidden dimension for channel-mixing MLP\n",
    "#         image_size=32,       # CIFAR 32x32\n",
    "#         in_channels=3        # (RGB)\n",
    "#     )\n",
    "# model.to(device)\n",
    "\n",
    "model = MlpMixer(\n",
    "        num_classes=100,     # 100 classes\n",
    "        num_blocks=16,        \n",
    "        patch_size=2,       \n",
    "        hidden_dim=1024,      # Hidden channel size\n",
    "        tokens_mlp_dim=512,   # Hidden dimension for token-mixing MLP\n",
    "        channels_mlp_dim=4096, # Hidden dimension for channel-mixing MLP\n",
    "        image_size=32,       # CIFAR 32x32\n",
    "        in_channels=3        # (RGB)\n",
    "    )\n",
    "model.to(device)\n",
    "    \n",
    "# optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-3, weight_decay=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "num_epochs = 100  # small number in paper went till 300\n",
    "\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Starting training on CIFAR-100\")\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, trainloader, criterion, optimizer, device)\n",
    "        test_acc = evaluate(model, testloader, device)\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "    \n",
    "print(\"Training complete :)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
